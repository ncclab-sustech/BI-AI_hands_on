{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "In this part, you will train a vanilla RNN language model on《论语》and evaluate its perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary: 1352\n"
     ]
    }
   ],
   "source": [
    "input_file = '../data/lunyu_20chapters.txt'\n",
    "\n",
    "from util import CorpusReader\n",
    "corpus = CorpusReader(inputFileName=input_file, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ###\n",
    "# Modify word2id to make 0 as the padding token '[PAD]', and increase the index of all other words by 1\n",
    "# Modify the id2word list to make the first word '[PAD]' as well\n",
    "# Hint: Both word2id and id2word in utils.CorpusReader are dict objects\n",
    "word2id = {}\n",
    "word2id['[PAD]'] = 0\n",
    "for word, id in corpus.word2id.items():\n",
    "    word2id[word] = id + 1\n",
    "\n",
    "id2word = {}\n",
    "id2word[0] = '[PAD]'\n",
    "for id, word in corpus.id2word.items():\n",
    "    id2word[id + 1] = word\n",
    "### END YOUR CODE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2word: [(0, '[PAD]'), (1, '，'), (2, '子'), (3, '。'), (4, '：')]\n",
      "word2id: [('[PAD]', 0), ('，', 1), ('子', 2), ('。', 3), ('：', 4)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test result\n",
    "print('id2word:', sorted(list(id2word.items()), key=lambda x: x[0])[:5])\n",
    "print('word2id:', sorted(list(word2id.items()), key=lambda x: x[1])[:5])\n",
    "\n",
    "# You should expect to see:\n",
    "# id2word: [(0, '[PAD]'), (1, '，'), (2, '子'), (3, '。'), (4, '：')]\n",
    "# word2id: [('[PAD]', 0), ('，', 1), ('子', 2), ('。', 3), ('：', 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 393])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    max_len = max([len(line.strip()) for line in lines])\n",
    "line_words = [list(line.strip()) for line in lines]\n",
    "seq_ids = [torch.tensor([word2id.get(word, 0) for word in words]) for words in line_words]\n",
    "seq_lens = torch.tensor([len(ids) for ids in seq_ids])\n",
    "seq_ids_padded = nn.utils.rnn.pad_sequence(seq_ids, batch_first=True)\n",
    "seq_ids_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_lunyu = nn.Embedding(len(word2id), 50) # vocab_size, embedding_dim\n",
    "rnn_lunyu = nn.RNN(50, 100, batch_first=True)\n",
    "seq_embs = embedding_lunyu(seq_ids_padded)\n",
    "seq_embs_packed = nn.utils.rnn.pack_padded_sequence(seq_embs, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "out_packed, _ = rnn_lunyu(seq_embs_packed)\n",
    "out_unpacked, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:  393\n",
      "seq_ids_padded: torch.Size([512, 393])\n",
      "seq_embs: torch.Size([512, 393, 50])\n",
      "out_unpacked: torch.Size([512, 393, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test result\n",
    "print('max length: ', max_len)\n",
    "print('seq_ids_padded:', seq_ids_padded.size())\n",
    "print('seq_embs:', seq_embs.size())\n",
    "print('out_unpacked:', out_unpacked.size())\n",
    "\n",
    "# You should expect to see:\n",
    "# seq_ids_padded: torch.Size([512, 393])\n",
    "# seq_embs: torch.Size([512, 393, 50])\n",
    "# out_unpacked: torch.Size([512, 393, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
       "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
       "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_ids_padded[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_padded = torch.zeros_like(seq_ids_padded)\n",
    "padding_id = 0\n",
    "\n",
    "for i in range(seq_ids_padded.size(0)):\n",
    "    targets_padded[i, :-1] = seq_ids_padded[i, 1:] # Shift the sequence to the left by 1\n",
    "    targets_padded[i, -1] = padding_id # Set the last token to be the padding token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets_padded: torch.Size([512, 393])\n",
      "last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "seq_ids_padded[0][:50]: tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
      "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
      "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n",
      "targets_padded[0][:50]: tensor([  5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,  15,\n",
      "        267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,  30,\n",
      "          9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "# Test result\n",
    "print('targets_padded:', targets_padded.size())\n",
    "print('last column of targets_padded:', targets_padded[:, -1][:10])\n",
    "\n",
    "print('seq_ids_padded[0][:50]:', seq_ids_padded[0][:50])\n",
    "print('targets_padded[0][:50]:', targets_padded[0][:50])\n",
    "\n",
    "# You should expect to see:\n",
    "# targets_padded: torch.Size([512, 393])\n",
    "# last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets_padded: torch.Size([512, 393])\n",
      "last column of targets_padded[:20]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "seq_ids_padded[0][:50]: tensor([  2,   5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,\n",
      "         15, 267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,\n",
      "         30,   9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n",
      "targets_padded[0][:50]: tensor([  5,   4,  47,   9, 225, 545,   6,   1,   7,  66, 131,  20,  10,  15,\n",
      "        267, 132, 106, 179, 246,   1,   7,  66,  64,  20,  10,  12,   7,  30,\n",
      "          9,   7, 546,   1,   7,  66,  19,   2,  20,  10,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "train_seq_ids = seq_ids\n",
    "train_seq_lens = seq_lens\n",
    "\n",
    "### START YOUR CODE ###\n",
    "targets_padded = torch.zeros_like(seq_ids_padded)\n",
    "padding_id = 0\n",
    "\n",
    "for i in range(seq_ids_padded.size(0)):\n",
    "    targets_padded[i, :-1] = seq_ids_padded[i, 1:] # Shift the sequence to the left by 1\n",
    "    targets_padded[i, -1] = padding_id # Set the last token to be the padding token\n",
    "\n",
    "### END YOUR CODE ###\n",
    "\n",
    "# Test result\n",
    "print('targets_padded:', targets_padded.size())\n",
    "print('last column of targets_padded[:20]:', targets_padded[:, -1][:20])\n",
    "\n",
    "print('seq_ids_padded[0][:50]:', seq_ids_padded[0][:50])\n",
    "print('targets_padded[0][:50]:', targets_padded[0][:50])\n",
    "# You should expect to see:\n",
    "# targets_padded: torch.Size([16, 85])\n",
    "# last column of targets_padded: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1353, 50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rand = nn.Embedding(len(word2id), 50, padding_idx=0)\n",
    "embedding_rand.weight.data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture\n",
    "\n",
    "<img src=\"../images/rnn_lm.png\" alt=\"RNN LM\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, embedding: nn.Embedding):\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.rnn = nn.RNN(embedding.embedding_dim, hidden_size=100, batch_first=True)\n",
    "        self.fc = nn.Linear(100, len(word2id))\n",
    "        \n",
    "\n",
    "    def forward(self, seq, seq_lens): # pass in raw word ids and sequence lengths\n",
    "        padded_seqs = nn.utils.rnn.pad_sequence(seq, batch_first=True)\n",
    "        padded_embs = self.embedding(padded_seqs)\n",
    "        packed_embs = nn.utils.rnn.pack_padded_sequence(padded_embs, seq_lens.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out_packed, _ = self.rnn(packed_embs)\n",
    "        out_unpacked, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        # print(out_unpacked.size()) # ([512, 393, 100])\n",
    "        logits = self.fc(out_unpacked)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model_rand = RNNLM(embedding_rand)\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alex\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.NLLLoss(ignore_index=0, reduction='none')\n",
    "optimizer = optim.Adam(model_rand.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture\n",
    "\n",
    "<img src=\"../images/perplexity.png\" alt=\"perplexity\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: RNNLM, seq, seq_len, targets_padded, loss_fn, optimizer, n_epochs=10):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model.forward(seq, seq_len)\n",
    "\n",
    "        loss = loss_fn(log_probs.view(-1, len(word2id)), targets_padded.view(-1))\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        perplexity = torch.exp(loss)        \n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}, Perplexity: {perplexity.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: RNNLM, seq, seq_len, targets_padded, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model.forward(seq, seq_len)\n",
    "        loss = loss_fn(log_probs.view(-1, len(word2id)), targets_padded.view(-1))\n",
    "        loss = loss.mean()\n",
    "        perplexity = torch.exp(loss)\n",
    "        print(f'Evaluation Loss: {loss.item()}')\n",
    "        print(f'Perplexity: {perplexity.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.6947746872901917, Perplexity: 2.0032577514648438\n",
      "Epoch 2/25, Loss: 0.6268472075462341, Perplexity: 1.8717001676559448\n",
      "Epoch 3/25, Loss: 0.5019248127937317, Perplexity: 1.6518977880477905\n",
      "Epoch 4/25, Loss: 0.4673384130001068, Perplexity: 1.5957412719726562\n",
      "Epoch 5/25, Loss: 0.46292901039123535, Perplexity: 1.5887205600738525\n",
      "Epoch 6/25, Loss: 0.4716038107872009, Perplexity: 1.6025623083114624\n",
      "Epoch 7/25, Loss: 0.4523650109767914, Perplexity: 1.5720256567001343\n",
      "Epoch 8/25, Loss: 0.4347092807292938, Perplexity: 1.5445139408111572\n",
      "Epoch 9/25, Loss: 0.4207722842693329, Perplexity: 1.5231374502182007\n",
      "Epoch 10/25, Loss: 0.40994134545326233, Perplexity: 1.5067293643951416\n",
      "Epoch 11/25, Loss: 0.3994125723838806, Perplexity: 1.4909486770629883\n",
      "Epoch 12/25, Loss: 0.389690101146698, Perplexity: 1.4765231609344482\n",
      "Epoch 13/25, Loss: 0.3803129196166992, Perplexity: 1.4627422094345093\n",
      "Epoch 14/25, Loss: 0.37196075916290283, Perplexity: 1.4505760669708252\n",
      "Epoch 15/25, Loss: 0.36348357796669006, Perplexity: 1.4383312463760376\n",
      "Epoch 16/25, Loss: 0.35459306836128235, Perplexity: 1.4256004095077515\n",
      "Epoch 17/25, Loss: 0.3460848033428192, Perplexity: 1.413522481918335\n",
      "Epoch 18/25, Loss: 0.3382508456707001, Perplexity: 1.4024922847747803\n",
      "Epoch 19/25, Loss: 0.33092355728149414, Perplexity: 1.3922533988952637\n",
      "Epoch 20/25, Loss: 0.3237936496734619, Perplexity: 1.3823620080947876\n",
      "Epoch 21/25, Loss: 0.31688782572746277, Perplexity: 1.3728485107421875\n",
      "Epoch 22/25, Loss: 0.31024956703186035, Perplexity: 1.3637654781341553\n",
      "Epoch 23/25, Loss: 0.30370354652404785, Perplexity: 1.3548673391342163\n",
      "Epoch 24/25, Loss: 0.29737919569015503, Perplexity: 1.3463257551193237\n",
      "Epoch 25/25, Loss: 0.2913552522659302, Perplexity: 1.3382399082183838\n"
     ]
    }
   ],
   "source": [
    "train(model_rand, seq_ids, seq_lens, targets_padded, loss_fn, optimizer, n_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity (on training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the perplexity by exponentiating the average loss per sequence.\n",
    "\n",
    "See the documentation here: https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.28542959690093994\n",
      "Perplexity: 1.3303333520889282\n"
     ]
    }
   ],
   "source": [
    "# random embedding\n",
    "evaluate(model_rand, seq_ids, seq_lens, targets_padded, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(model, seq, max_length=20):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        current_tokens = seq\n",
    "        for _ in range(max_length):\n",
    "            current_tokens_tensor = torch.tensor([[word2id[word] for word in current_tokens]])\n",
    "            seq_lens = torch.tensor([len(current_tokens)])\n",
    "            # 调用模型，获取下一个单词的概率分布\n",
    "            log_probs = model(current_tokens_tensor, seq_lens)\n",
    "            # 从概率分布中采样下一个单词的索引\n",
    "            next_word_index = torch.argmax(log_probs[:, -1, :], dim=-1).item()\n",
    "            next_word = id2word[next_word_index]\n",
    "            current_tokens.append(next_word)\n",
    "            if next_word == '。':\n",
    "                break\n",
    "        return ''.join(current_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'天下之，曰：不知也。'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = ['天','下']\n",
    "max_length = 20\n",
    "get_sentence(model_rand, seq, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'子曰：君子有三戒，不亦可谓也。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = ['子','曰']\n",
    "max_length = 20\n",
    "get_sentence(model_rand, seq, max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
