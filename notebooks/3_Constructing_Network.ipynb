{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2ccb11-d6e5-4c0b-b430-3330334eaaeb",
   "metadata": {},
   "source": [
    "# üí™ Part 3: Building and Training Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5272d7-5eb3-4585-ab66-1415dbe7ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import torch \n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from helper import helper\n",
    "\n",
    "random.seed(2021) # We set a seed to ensure our samples will be the same every time we run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c91d0-748f-4c58-9143-7f64bcaff57f",
   "metadata": {},
   "source": [
    "## ‚öóÔ∏è The Data Science Pipleine \n",
    "*This section will be repeated in both Part 2 and Part 3*\n",
    "\n",
    "> What on earth is data science?! -- George Washington (probably not)\n",
    "\n",
    "Seriously though, nowadays, in such a data-rich world, data science has become the new buzzword, the new cool kid in the block. But what exactly is it? Unfortunately, no one can really pin down a [rigourous definition](https://hdsr.mitpress.mit.edu/pub/jhy4g6eg/release/7) of data science. At the high level:\n",
    "\n",
    "> Data science is the systematic extraction of novel information from data.\n",
    "\n",
    "Good enough! With this definition, most practitioners can somewhat agree on a pipeline or flow. Here are the steps:\n",
    "1. Identify your problem (What are you trying to do?)\n",
    "2. Obtain your data (What resource do we have to work with?)\n",
    "3. Explore your data (What does our data actually look like?)\n",
    "4. Prepare your data (How do we clean/wrangle our data to make it ingestible?)\n",
    "5. Model your data (How do we automate the process of drawing out insights?)\n",
    "6. Evaluate your model (How good are our predictions?)\n",
    "7. Deploy your model (How can the wider-user base access these insights?)\n",
    "\n",
    "The 7th step is out-of-scope for this workshop, but we well be exploring the other steps to varying degrees:\n",
    "* Steps 1-4 will be explored in Part 2.\n",
    "* Steps 5-6 will be explored in Part 3 and 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d477b-c2b9-4f3f-a07d-75e893797252",
   "metadata": {},
   "source": [
    "## üß¢ Recap\n",
    "Let's review what we have done so far:\n",
    "\n",
    "|Pipeline | Our Problem |\n",
    "|---| --- |\n",
    "|1. Identify Your Problem | Classify images of items of clothing |\n",
    "|2. Obtain Your Data | 70,000 labelled images (10 different types) of clothes |\n",
    "|3. Explore Your Data | Class distribution perfectly equal across classes |\n",
    "|4. Prepare Your Data | Split 70,000 into 60,000 train and 10,000 test set |\n",
    "\n",
    "Note that we didn't have to do too much cleaning because the data we have is close to *perfect* in many regards. For further details about intricacies of this process, this excellent [textbook](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) provides all the nitty gritty detail. \n",
    "\n",
    "We need to re-run the data reading part of the tutorial from the last notebook. Please set your variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb212e9-9bf7-4713-ad38-ef36a2825bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the function without running it\n",
    "def load_data_fashion_mnist(batch_size, n_workers):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                    train=True,\n",
    "                                                    transform=trans,\n",
    "                                                    download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                   train=False,\n",
    "                                                   transform=trans,\n",
    "                                                   download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=n_workers),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=n_workers))\n",
    "\n",
    "# Then execute the function here\n",
    "batch_size = 512  # Set to 256 on your own device\n",
    "n_workers = 0      # Set to 4 on your own device\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size, n_workers = n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcea701-25a1-462f-a050-7ab5d966df99",
   "metadata": {},
   "source": [
    "## Step 5A: Setting Up Your Model\n",
    "Our data is fully prepared and we are ready to go! üöÄüöÄüöÄ A recap on neural networks:\n",
    "* Building Blocks = Perceptrons\n",
    "* Many Perceptrons = Multi-Layer Perceptrons (MLP)\n",
    "* Extension to Images = Convolutional Neural Networks\n",
    "\n",
    "### ü™ü Convolutional Neural Network\n",
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This part is the most conceptually confusing -- ask lots of questions here! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "\n",
    "* Typical MLPs are weak for image recognition ‚ùÑÔ∏è\n",
    "* We need some image pre-processing to bolster performance üí™\n",
    "* We use [convolution](https://en.wikipedia.org/wiki/Convolution#Visual_explanation) (and pooling) to do that, which is effectively a sliding window ü™ü \n",
    "\n",
    "![](../images/convolution.gif)  \n",
    "[source](https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Full_padding_no_strides.gif)\n",
    "\n",
    "### LeNet\n",
    "The particular convolutional neural network architecture we will use is called the LeNet. It was one of the first successful neural network architectures to be concieved by Yann LeCun as he worked at Bell Laboratory. Here is the [original paper](https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition) if you are interested. In this instance, we will be building a slightly adapted version that the d2l.ai textbook outlines in [this chapter](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html). (The key difference is that we will be dropping the Gaussian activation function in the final layer).\n",
    "\n",
    "We will be using the two diagrams below to construct our neural network:\n",
    "\n",
    "![lenet](../images/lenet.svg)\n",
    "\n",
    "**Figure 1:** The architecture of LeNet. ([source](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html))\n",
    "\n",
    "![lenetsimple](../images/lenet-vert.svg)\n",
    "\n",
    "**Figure 2:** Compact version of the architecture of LeNet. ([source](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html))\n",
    "\n",
    "LeNet layers summary:\n",
    "\n",
    "| Layer | Dimensions | Purpose |\n",
    "| --- | --- | --- |\n",
    "| Convolution | 2D | Draw out 'patterns' in the image |\n",
    "| Pooling | 2D | Compress image |\n",
    "| Flattening | 2D -> 1D | Convert to 1D |\n",
    "| Dense/Linear | 1D | Typical MLP |\n",
    "\n",
    "#### üßÖ Convolution Layers\n",
    "The convolution layer is effectly the 'sliding window' part of the CNN. It takes in 4 hyperparameters. From Figure 2, we can determine the values of the first convolutional layer.\n",
    "\n",
    "| Hyperparameter | Description | First Layer Values |\n",
    "| --- | --- | --- |\n",
    "| Kernel Size | Size of window | 5 (5x5) | \n",
    "| Output Layers | Number of filters/channels | 6 |\n",
    "| Padding | Size of the '0' ring | 2 |\n",
    "| Stride | How far to slide the window | 1 |\n",
    "\n",
    "***If not stated, default Pad is 0 and Stride is 1.***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcececf-394c-4cce-8357-ad8887f0a387",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='#F89536'> **Discussion:** </font>\n",
    "If the input image is 28x28, what are the output dimensions of the layer? (Hint: With pad-2, the image will be a 32x32 image. How many strides (of 1) can the window move horizontally before reaching the right-hand side?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a3a3b-5317-450d-950f-c0fbbc8be11a",
   "metadata": {},
   "source": [
    "Since our images are black and white, there is only a single input channel. In code, this looks like:  \n",
    "`nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size=5, padding=2)`.\n",
    "\n",
    "**Note:** If you want to get a more conceptual understanding of what is happening, [this Stanford University course](https://cs231n.github.io/convolutional-networks/) has an animated figure which you can toggle on and off. The 'window' and the 'filter' matrices are combined via a [cross-correlation](http://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html?highlight=cross%20correlation) operation.\n",
    "\n",
    "#### üßÖ Pooling Layers\n",
    "All pooling in LeNet is average pooling. It takes in two hyperparameters. From Figure 2, we can determine the values of the first pooling layer.\n",
    "\n",
    "| Hyperparameter | Description | First Layer Values |\n",
    "| --- | --- | --- |\n",
    "| Kernel Size | Size of window | 2 (2x2) | \n",
    "| Stride | How far to slide the window | 2 |\n",
    "\n",
    "Putting this together, the code becomes: `nn.AvgPool2d(kernel_size=2, stride=2)`.\n",
    "\n",
    "\n",
    "#### üßÖ Linear/Dense Layer\n",
    "The first dense (fully-connected) layer is FC(120) in Figure 2. The input is 16 layers of 5x5 images. How many pixels is that in total?  \n",
    "$$16 \\times 5 \\times 5 = 400$$\n",
    "\n",
    "Thus for this layer, the input dimension is 400, and the output is 120. \n",
    "\n",
    "Putting this together, the code becomes: `nn.Linear(in_features = 16 * 5 * 5, out_features = 120)`.\n",
    "\n",
    "\n",
    "#### ü™¢ Tying Loose Ends\n",
    "* Between each layer, we add a sigmoid function `nn.Sigmoid()` as our activation function\n",
    "* Pooling layers do not need activation functions after them (only convolutional and linear)\n",
    "* The final layer does not use an activation function\n",
    "* To flatten the 2D image into 1D line so it can put into an MLP, we use the `nn.Flatten()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364ff65-3b64-4d85-b177-587b141158cf",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='#F89536'> **Your Turn!** </font> \n",
    "What are the hyperparameters for the *second* convolutional, pooling, and linear layers? Fill in the `?` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61077e2f-52ee-45e7-8b32-e788fba87b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LeNet Architecture\n",
    "net = nn.Sequential(nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels = ?, out_channels = ?, kernel_size=?), ?,\n",
    "                    ?, nn.Flatten(),\n",
    "                    nn.Linear(in_features = 16 * 5 * 5, out_features = 120), ?,\n",
    "                    ?, ?, \n",
    "                    nn.Linear(in_features = 84, out_features = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ddfee-4eeb-4a1d-a4a1-b50d9bb19b17",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576944d3-f49e-490a-b352-4540c4429dd9",
   "metadata": {},
   "source": [
    "Let's have a look at what each layer looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18e770-fe1a-4b36-b30b-c4fb133a948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show layers\n",
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:    \\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b131316-cbf8-4d6d-8677-76604e785b0a",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='#F89536'> **Discussion** </font> \n",
    "Does this match with the LeNet architecture we outlined at the beginning?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75e678-e8ea-4139-9bdb-c6b8cf0b21ea",
   "metadata": {},
   "source": [
    "## Step 5B: Training Your Model\n",
    "\n",
    "### Initialising weights\n",
    "* When you setup your neural network `net` the values are complete garbage\n",
    "* You want to initialise your weights randomly, but in a systematic way (valuable garbage)\n",
    "* We use the [Xavier Uniform](https://pytorch.org/docs/stable/nn.init.html#) distribution as outlined in [this paper](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c99d04-b35f-4dfb-9c04-46ad8588df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # We will only set the weights from linear and Conv2d layers, since pooling layers do not require this\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights) # the function apply() takes in another function as input! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1e570-18d1-497b-a17d-024da8c8af59",
   "metadata": {},
   "source": [
    "### Setting Hyperparameters\n",
    "There are certain hyperparameters associated with the training phase we need to set:\n",
    "\n",
    "| Hyperparameter | Description | Selected Value |\n",
    "| --- | --- | --- |\n",
    "| Learning Rate | How quickly the algorithm converges. Too quick and we might *miss* the optimal weights. Too slow and it will take a long time to run | $0.9$ |\n",
    "| Optimiser | What algorithm do we use to find the optimal weights? | [Stochastic Gradient Descent (SGD)](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) |\n",
    "| Loss Function | How do we measure the *correctness* of our predictions? | [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) |\n",
    "\n",
    "We define these below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7b334-b6d2-419e-bdf5-646d115dbb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.9 \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr) \n",
    "loss = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b03103-5f9f-4314-844d-8ed8fce1311e",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "To train the model we must:\n",
    "1. Set the 'mode' of the network to `train` üöÖ\n",
    "2. Select a single mini-batch to train on ‚úÖ\n",
    "3. Conduct a forward pass to make predictions ‚û°Ô∏è\n",
    "4. Calculate the loss (lack of 'correctness') of these predictions üßÆ\n",
    "5. Calculate the gradients required for back propagation (according to the loss function) üßÆ\n",
    "6. Update weights according to gradient descent ‚¨ÖÔ∏è\n",
    "\n",
    "Each line below corresponds to each of these steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2673e4c-b7e0-4f71-b7c4-90c7323577f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train() # This doesn't actually train, but sets the network on training mode\n",
    "X, y = next(iter(train_iter)) # Pick a single minibatch at random to do the training\n",
    "optimizer.zero_grad() # before running the forward/backward pass we need to reset the gradient (otherwise it accumulates)\n",
    "y_hat = net(X) # Forward pass on the data to make prediction\n",
    "l = loss(y_hat, y) # calculate the loss \n",
    "l.backward() # calculate gradients for back prop\n",
    "optimizer.step() # step forward in optimisation and apply backprop to update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8adee2-55a7-4d6c-ba5b-3162da3e5b7f",
   "metadata": {},
   "source": [
    "### üéâüéâüéâ Congratulations! You have trained your first neural network in PyTorch üéâüéâüéâ\n",
    "\n",
    "...well not quite. This model is going to be quite terrible, since we only trained on a small sample of our dataset. In the next part we will look into scaling this procedure up. But first, let's see how we went.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc745c0-3d6a-4b0f-8bb1-4843fcd188ae",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Your Model\n",
    "It's all well and good if you can train a model, but it's pretty useless if you can't see how well it does. Recall that our performance metric is that we want:\n",
    "* Predictions to be correct (Accuracy)\n",
    "* Model to generalise to unseen data (No Overfitting)\n",
    "\n",
    "Thus we should extract both the train accuracy (how well the model runs on the dataset it trained on), and the test accuracy (how well the model runs on unseen/independent data).\n",
    "\n",
    "### Training Accuracy\n",
    "First we calculate the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fcb37-c33f-417e-a534-6a9792d29892",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = l * X.shape[0]\n",
    "n_correct = helper.accuracy(y_hat, y)\n",
    "n_total = X.shape[0] \n",
    "\n",
    "print(\"1. The mini-batch loss is: \\t\\t\\t\\t\", loss)\n",
    "print(\"2. The number of correct training predictions is: \\t\", n_correct)\n",
    "print(\"3. The number of total training predictions is: \\t\", n_total)\n",
    "\n",
    "print(\"This means we get a training accuracy of \", n_correct/n_total)\n",
    "print(\"The average loss for each example is \", float(loss/n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8df3da-e8c3-4f35-a5d5-4219316ff7f2",
   "metadata": {},
   "source": [
    "### Testing Accuracy\n",
    "Then we calculate the testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ca85a-e47b-4bdf-b8be-7c8d4d5a1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = helper.evaluate_accuracy(net, test_iter)\n",
    "print(\"The testing accuracy is: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ba65e-45cd-450d-939c-fdf95ce5b5a1",
   "metadata": {},
   "source": [
    "| Dataset | Accuracy |\n",
    "| --- | --- |\n",
    "| Train | ~10% |\n",
    "| Test | ~10% |\n",
    "\n",
    "This is no better than randomly assigning (since we would have a 1 in 10 chance of being correct)! But we are not finished yet, let's now scale our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-tutorial",
   "language": "python",
   "name": "cnn-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
